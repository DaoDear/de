# Lab 3 : Kafka (Part 2)

## 3.4 Kafka Streams Integration With Java (Streaming Data Using Kafka Streams to Count Words)

#### 1) เปิด Kafka Sever โดยตั้งค่าตามไฟล์ config/server.properties
```
[TERMINAL#1]
$ source ~/.bash_profile.kafka
$ sudo zookeeper-server start
$ cd ~/kafka
$ bin/kafka-server-start.sh config/server.properties &
```

#### 2) สร้าง topic ชื่อ streams-plaintext-input และ streams-wordcount-output
```
[TERMINAL#1]

$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic streams-plaintext-input

ตัวอย่าง Output ที่ได้จากคำสั่งข้างต้น:
Created topic streams-plaintext-input.

$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic streams-wordcount-output --config cleanup.policy=compact

ตัวอย่าง Output ที่ได้จากคำสั่งข้างต้น:
Created topic streams-wordcount-output.

$ bin/kafka-topics.sh --zookeeper localhost:2181  --describe
```

#### 3) เรียก Java class file ที่ชื่อว่า WordCountDemo
```
[TERMINAL#1]

$ bin/kafka-run-class.sh org.apache.kafka.streams.examples.wordcount.WordCountDemo
```
 
#### 4) เปิด producer console สำหรับ topic ชื่อ streams-plaintext-input
```
[open new terminal: TERMINAL#2]
$ source ~/.bash_profile.kafka
$ cd ~/kafka
$ bin/kafka-console-producer.sh --broker-list localhost:9092  --topic streams-plaintext-input
```
 
#### 5) เมื่อปรากฏ console prompt รูปเครื่องหมายมากกว่า (>) ให้ทำการส่งข้อความผ่าน producer console แล้วกด Ctrl+C (^C) เพื่อจบการทำงานของ producer console
```
[TERMINAL#2]

> Hello Kafka
> Hello Big Data 
> Hello Data Engineer
^C
```
 
#### 6) เปิด consumer console สำหรับ streams-wordcount-output
```
[TERMINAL#2]

$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic streams-wordcount-output --from-beginning --formatter kafka.tools.DefaultMessageFormatter --property print.key=true --property print.value=true --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer

ตัวอย่าง Output ที่ได้จากคำสั่งข้างต้น:
hello     1
kafka     1
hello     2
big       1
data      1
hello     3
data      2
engineer  1
```
กด Ctrl+C (^C) เพื่อจบการทำงาน
```
^C
```
 
#### 7) ปิด Terminal#2 กลับไปใช้ Terminal#1 

#### 8) เมื่อกลับไปที่ Terninal#1 แล้ว ให้กด Ctrl+C เพื่อปิดคำสั่งที่กำลังทำงานอยู่และทำ lab ต่อไป

## 3.5 Integration With Spark

#### 9)	สร้าง topic และเรียกโปรแกรม spark
```
[TERMINAL#1]

$ source ~/.bash_profile.kafka
$ cd ~/kafka

$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic labspark

$ cd ~/kafka/lab3.5

$ spark-submit spark-direct-kafka.py localhost:9092 labspark
```

#### 10) เปิด producer console
```
[Open new terminal: TERMINAL#2]

$ source ~/.bash_profile.kafka
$ cd ~/kafka
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic labspark
```

#### 11) เมื่อปรากฎ console prompt รูปเครื่องหมายมากกว่า (>) ให้ทำการส่งข้อความผ่าน producer console 
```
[TERMINAL#2]

> Hello World
> Hello Mars
> Hello Kitty
```

#### 12) สลับไปดูผลลัพธ์ใน Terminal#1
#### 13) เมื่อผลทดลองเป็นที่น่าพอใจ ให้ปิด Terminal#2 กลับไปใช้ Terminal#1 
#### 14) เมื่อกลับไปที่ Terninal#1 แล้ว ให้กด Ctrl+C เพื่อปิดคำสั่งที่กำลังทำงานอยู่และทำ lab ต่อไป

## 3.6 Integration With Flume

#### 15) สร้าง topic ชื่อ lab_kafka_flume
```

```
#### 16) เรียก flume agent
```

```
#### 17) เปิด producer console 
```

```
#### 18) เมื่อปรากฏ console prompt รูปเครื่องหมายมากกว่า (>) ให้ทำการส่งข้อความ
```

```
#### 19) ดูผลลัพธ์ใน HDFS
```
[Open new terminal: TERMINAL#3]

$ hdfs dfs -ls /tmp/kafka/lab_kafka_flume/20-07-22/

ตัวอย่างชื่อไฟล์ ที่ได้จากคำสั่งข้างต้น:
/tmp/kafka/lab_kafka_flume/20-07-22/FlumeData.xxxxxxxxx

$ hdfs dfs -cat /tmp/kafka/lab_kafka_flume/20-07-22/FlumeData.xxxxxxxxx

```
